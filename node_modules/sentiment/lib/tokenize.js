/**
 * Remove special characters and returns an array of tokens (words).
 *
 * @param   {string}  input
 *
 * @return  {array}
 */
 
var fs = require("fs");
var async = require("async");
/* ORIGINAL
module.exports = function (input) {
    return input
        .toLowerCase()
        .replace(/[^a-z0-9á-úñäâàéèëêïîöôùüûœç\- ]+/g, '')
        .replace('/ {2,}/',' ')
        .split(' ');
};
*/


exports.tokenize_words = function (input) {
    return input
        .toLowerCase()
        .replace('/ {2,}/',' ')
        .split(' ');
};

exports.tokenize_phrases = function (input) {
    
    fs.readFile('../build/emoticons.txt', function (err, data) {
        var lines = data.toString().split(/\n/);
        async.forEach(lines, function (obj, callback) {
            var item = obj.split(/[\t\s]/);
            input.replace(item[1],item[1]+'.');
            callback();
        }, function (err) {
            if (err) throw new Error(err);
        });
        
    });
    return input
        .toLowerCase()
        .replace('/ {2,}/',' ')
        .split('/[\.\!\?]+/');
}

